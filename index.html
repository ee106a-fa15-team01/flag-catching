<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Flag catching by ee106a-fa15-team01</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Flag catching</h1>
      <h2 class="project-tagline">Final project for EE 106A Fall 2015</h2>
      <a href="https://github.com/ee106a-fa15-team01/flag_catching" class="btn">View on GitHub</a>
      <a href="https://github.com/ee106a-fa15-team01/flag_catching/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/ee106a-fa15-team01/flag_catching/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h1>

<h2>
<a id="end-goals" class="anchor" href="#end-goals" aria-hidden="true"><span class="octicon octicon-link"></span></a>End goals</h2>

<p>The runner Zumy should reach the goal and return to its home region afterward without touched by the chaser Zumy. For chaser     Zumy, to catch the runner is the only thing it has to do.</p>

<p>That is, the goal for the runner is first the flag then the home region. At the same time, the chaser is an obstacle for it. Vice and versa, the runner is the goal for the chaser and the other chasers are obstacles for it.
pic 2 and pic 3 here (parallel would be nice)</p>

<p>The runner should be able to identify and also locate the goal, home region and the point where the chaser locates at. Based on these information, we can calculate the potential field for the current location. By comparing the magnitude of the potential field we got from the function, the latest coordinate for next step can be found. </p>

<p>By comparing the current location of the Zumy seen by the camera with the new coordinate for next step, we can assign the Zumy toward that point till it reaches the point.</p>

<p>Since all the chaser are designed to avoid other chasers, it tends to approach the runner from different directions which could make them easier to win compared to the runner.</p>

<h2>
<a id="why-is-it-interesting" class="anchor" href="#why-is-it-interesting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why is it interesting?</h2>

<p>The idea is based on a video game called pac-man. It would be an interesting game base on the reason that many unpredictable elements in the real world may affect the game result which could barely be observed only by coding. Besides, we can add more than one chaser in this game and to see how the runner escapes from of be caught by them.</p>

<p>Another interesting part for this project is the implementation of potential field hence optimize our controlling on path planning. For this part, we modify our ways of calculating the potential field over and over again by observing the real results happened on the game field. </p>

<p>The problems we have to solve are listed below:
1. How to avoid obstacles and move to objects?
2. How to locate each objects seen in either the camera frame or ground frame?
3. How to control the Zumys well during the game?</p>

<h2>
<a id="applications-in-real-world" class="anchor" href="#applications-in-real-world" aria-hidden="true"><span class="octicon octicon-link"></span></a>Applications in real-world</h2>

<ol>
<li>Highly-autonomous cars</li>
<li>Increase human safety:<br>
Automatic industrial fork truck (trucks with a function of picking up goods at a given location or carry it back to an    assigned home region. The trucks should be able to avoid other trucks and people during the task).</li>
<li>Autonomous constructional vehicles which pedrail wheels are used for   them, so they tend to have similar moving pattern to Zumy due to the friction conditions. Based on this, the way of controlling the pedrail system should be similar).</li>
</ol>

<h1>
<a id="design" class="anchor" href="#design" aria-hidden="true"><span class="octicon octicon-link"></span></a>Design</h1>

<h2>
<a id="design-criteria" class="anchor" href="#design-criteria" aria-hidden="true"><span class="octicon octicon-link"></span></a>Design criteria</h2>

<h3>
<a id="hardware-constructions" class="anchor" href="#hardware-constructions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hardware constructions</h3>

<ol>
<li>If N Zumys are set in the game, N+3 AR tags in total( +3 each stands for the origin, the goal and one for boundary need) are needed.
c 4 here</li>
<li>The game field must be smaller than 90 (cm) x 105 (cm) regarding to the limitation of camera vision.</li>
<li>To minimize the errors of coordinate recognition, the camera are set to be on the right top of the origin AR tag</li>
<li>Fully charged batteries for Zumys is desirable in order to solve the problem caused by velocity differences between Zumys, but it has been solved by using PID controller on Zumy</li>
<li>All the AR tags should be recognized well by the camera all the time</li>
</ol>

<h3>
<a id="coordinate-transform" class="anchor" href="#coordinate-transform" aria-hidden="true"><span class="octicon octicon-link"></span></a>Coordinate transform</h3>

<ol>
<li>Scale the real world ground into a virtual grid</li>
<li>Using the camera to locate all the Zumys</li>
<li>Coordinate transform is completed by the tf. lookup transform which transforms the coordinate seen from the camera to the ground coordinate. </li>
<li>Ground frame is formed by placing an AR tag on the ground and set it to be the reference origin for this frame</li>
</ol>

<h3>
<a id="complete-path-planning-by-using-potential-field-method" class="anchor" href="#complete-path-planning-by-using-potential-field-method" aria-hidden="true"><span class="octicon octicon-link"></span></a>Complete path planning by using potential field method</h3>

<ol>
<li>Using the following function in our code:
U_obstacle=(1/√(1+〖dist(q,obstacle)〗^6 ))^2 dist(q, goal)^2, when p &gt; dist(q, obstacle)
U_obstacle = 0                              , when p &lt; dist(q, obstacle)
here</li>
<li>Make the potential field into a readable window which can show us the current potential field value for each current location. 
pic 6 here</li>
</ol>

<h2>
<a id="design-we-chose" class="anchor" href="#design-we-chose" aria-hidden="true"><span class="octicon octicon-link"></span></a>Design we chose</h2>

<h3>
<a id="hardware-constructions-1" class="anchor" href="#hardware-constructions-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hardware constructions</h3>

<p>"Zumy" is the robot we’re using in this project. It’s provided by EECS department in UC, Berkeley.<br>
 pic 7 here</p>

<h3>
<a id="coordinate-transform-1" class="anchor" href="#coordinate-transform-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Coordinate transform</h3>

<p>There are two ways to fulfill this part. The first one is using the camera on the Zumy itself. Difficulty is that it’s hard to locate every single Zumy in the world frame unless we have a visual map for them. The method we chose is based on using AR tags and one camera. It’s much simpler than the first one. </p>

<h3>
<a id="construct-path-planning-by-constructing-a-virtual-potential-field" class="anchor" href="#construct-path-planning-by-constructing-a-virtual-potential-field" aria-hidden="true"><span class="octicon octicon-link"></span></a>Construct path planning by constructing a virtual potential field</h3>

<p>We chose potential field instead of optimal control. One reason is potential field is easier to understand. The smaller the value of it, the higher preference for the object moving to it. The other reason is that we didn’t add cost and punishment to the steps the Zumy takes, so there’s no need to use other methods to do the motion planning. That is, potential field is a contrarily easier way for us to accomplish our design goals in an efficient way.</p>

<h3>
<a id="about-applying-discrete-or-continuous-time" class="anchor" href="#about-applying-discrete-or-continuous-time" aria-hidden="true"><span class="octicon octicon-link"></span></a>About applying discrete or continuous time</h3>

<p>As mentioned in the previous page, we scale the ground into grids which means the Zumys will move in a discrete way. In other words, Zumys will have to reach each current desired point or it won’t be able to do the next path planning. On the other hand, there’s a continuous time method. In this way, the Zumy will have a non-stop motion which means it can move faster. The problem is that it would cause location errors in the end which is hard to adjust. This problem is basically caused by hardware limitation, such as drifting problems. It happens especially when the velocity changes from angular to linear.    </p>

<h2>
<a id="impactions-encountered" class="anchor" href="#impactions-encountered" aria-hidden="true"><span class="octicon octicon-link"></span></a>Impactions Encountered</h2>

<ol>
<li>The runner Zumy got trapped by the local minima (minimum potential field value) which means it will stay in that current location all the time.
If we got a video here!!!!! </li>
<li>The direction of moving objects aren’t taken into account. It may be an efficient way.</li>
<li>Errors caused by the hardware, such as camera and Zumys.</li>
<li>The method of controlling we’re using is discrete in time which means if the Zumy got trapped in a step (caused by reasons 1.), it won’t be able to do the next path planning (it stops) and caught by the chasers.</li>
</ol>

<h1>
<a id="implementation" class="anchor" href="#implementation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation</h1>

<h2>
<a id="hardware-description" class="anchor" href="#hardware-description" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hardware description</h2>

<p>pic 8</p>

<h2>
<a id="code-detail-diagram-flow-charts-launch-files-urdf" class="anchor" href="#code-detail-diagram-flow-charts-launch-files-urdf" aria-hidden="true"><span class="octicon octicon-link"></span></a>Code detail (diagram, flow charts, launch files, URDF….)</h2>

<h2>
<a id="describe-complete-system-work" class="anchor" href="#describe-complete-system-work" aria-hidden="true"><span class="octicon octicon-link"></span></a>Describe complete system work</h2>

<p>(rqt_graph) pic 9 here 
Zumy 5a is the runner; Zumy 1b and 1c are the catchers (three Zumys in total).
tf delivers the coordinates of the AR tags ( Zumys, origin and goal) to 5a,1b,1c. </p>

<p>The chaser Zumys are all sharing the same module to calculate the potential value while the runner Zumy only calculate its own potential field.</p>

<p>After the calculation, the grid with the smallest potential value will be chose as the next desired coordinate.</p>

<p>After knowing the next assigned point, the Zumys all share the same controlling code. The camera information is included in the code, so the Zumys can move to the next point according to the coordinate information. After finishing each step, coordinates will be evaluated to see if it’s already caught the flag or not. Either side who win the game will publish a "game over" message to the game status topic. All the Zumys are subscribed to this game status topic, so all the velocity commands on the Zummys will become zero (it stops).</p>

<h1>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h1>

<h2>
<a id="coordinate-transform-2" class="anchor" href="#coordinate-transform-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Coordinate transform</h2>

<p>It works quite well after we put an AR tag as a referenced origin. Of course adjust the camera configuration will minimize the error. Also, a filter is wrote in the code for Zumys to get rid of way-off information given from the camera.</p>

<h2>
<a id="complete-path-planning-by-using-potential-field-method-1" class="anchor" href="#complete-path-planning-by-using-potential-field-method-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Complete path planning by using potential field method</h2>

<p>In order to have a better insight of the parameters in the function we’re using. We test it out and then observe the result. The effective range of the obstacles can be adjusted by increasing or decreasing the parameters in the function. The function fits any situation now.</p>

<h2>
<a id="motion-of-the-zummy" class="anchor" href="#motion-of-the-zummy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Motion of the Zummy</h2>

<p>To improve the motion of Zumys and solve the problem list previously (problem 4.), a forward linear velocity is added to steps with pure rotation.  </p>

<h2>
<a id="final-video-picture" class="anchor" href="#final-video-picture" aria-hidden="true"><span class="octicon octicon-link"></span></a>Final Video, picture</h2>

<h1>
<a id="conclusion" class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h1>

<ol>
<li>Most of the coordinate errors have been eliminated.</li>
<li>The extra linear velocity added to the pure rotations doesn’t seem to be obvious. The reason is because of the scale for each grid is not big enough for us to see the curve path it performs. However, it keeps Zumys from trapping. </li>
<li>The function we’re using for calculating the potential field has been modified quite well. The runner can move forward to the flag and avoiding the chasers well at the same time. 
he performances of the chasers are good enough to catch the runner and keeps itself from crashing into other chasers.</li>
<li>We are able to stop the Zumy correctly by using the "game over" topic.</li>
</ol>

<h2>
<a id="particular-difficulties" class="anchor" href="#particular-difficulties" aria-hidden="true"><span class="octicon octicon-link"></span></a>Particular difficulties</h2>

<ol>
<li>Zumys lose connection to computers easily. </li>
<li>Better way of controlling the velocity of the Zumy.</li>
<li>The axis saw on rviz was flipping all the time because of the errors caused by the camera especially when two AR tags get too close to each other. </li>
<li>Continuous time method applied to Zumy’s motion turns out to have greater coordinate errors. Discrete method is contrarily a stable way to meet our goals.</li>
<li>Zumys get trapped in a local minima situation.</li>
</ol>

<h1>
<a id="improvements-in-the-future" class="anchor" href="#improvements-in-the-future" aria-hidden="true"><span class="octicon octicon-link"></span></a>Improvements in the future</h1>

<ol>
<li>Continuous time method should also work correctly. </li>
<li>Zumys shouldn’t be trapped in a local minimum value.<br>
</li>
<li>Filter used for the camera can be improved.</li>
<li>For "game over" topic, all the Zumys should stop immediately instead of finishing its current step then stop.</li>
<li>Try to optimize the effect between the chasers Zummy, so that chaser can cooperate with each other to catch the runner.</li>
<li>Try to apply kalman filter</li>
</ol>

<h1>
<a id="team-members" class="anchor" href="#team-members" aria-hidden="true"><span class="octicon octicon-link"></span></a>Team members</h1>

<h2>
<a id="liu-yang" class="anchor" href="#liu-yang" aria-hidden="true"><span class="octicon octicon-link"></span></a>Liu Yang</h2>

<p>A senior, exchange student from China, Beijing Institute of Technology majoring in Electrical Engineering</p>

<h2>
<a id="hsiu-wei-chang" class="anchor" href="#hsiu-wei-chang" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hsiu-Wei Chang</h2>

<p>A junior, exchange student from Taiwan, National Changhua University of Education majoring in Electrical Engineering.</p>

<h2>
<a id="rui-zhang-z-rui" class="anchor" href="#rui-zhang-z-rui" aria-hidden="true"><span class="octicon octicon-link"></span></a>Rui Zhang (<a href="https://github.com/z-rui" class="user-mention">@z-rui</a>)</h2>

<p>I am a junior student from <a href="http://www.njust.edu.cn/">Nanjing University of Science and Technology</a>. Good at Python and C programming. As an exchange student in Berkeley I took EE C106A, EE 120 and CS 61C this semester.</p>

<h2>
<a id="yang-yue" class="anchor" href="#yang-yue" aria-hidden="true"><span class="octicon octicon-link"></span></a>Yang Yue</h2>

<p>TODO</p>

<h1>
<a id="fail-videos" class="anchor" href="#fail-videos" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fail videos</h1>



      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/ee106a-fa15-team01/flag_catching">Flag catching</a> is maintained by <a href="https://github.com/ee106a-fa15-team01">ee106a-fa15-team01</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
